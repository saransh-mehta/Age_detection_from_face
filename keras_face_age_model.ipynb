{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "# In this we ll load the images, do pre processing to bring data in form \n",
    "# for training\n",
    "# build the cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the csv files and reading images according to it\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#reading train images, we already have saved resized images in train_new\n",
    "trainX = []\n",
    "for image in train.ID:\n",
    "    img = cv2.imread(os.path.join('train_new', image), cv2.IMREAD_COLOR)\n",
    "    img = np.array(img, dtype = 'float32')\n",
    "    trainX.append(img)\n",
    "trainX = np.array(trainX)    #or can use np.stack(trainX, axis = 0)\n",
    "#trainX.shape\n",
    "#trainX.reshape((len(train), 32, 32, 3))\n",
    "\n",
    "#similarly for test images\n",
    "testX = []\n",
    "for image in test.ID:\n",
    "    img = cv2.imread(os.path.join('test_new', image), cv2.IMREAD_COLOR)\n",
    "    img = np.array(img, dtype = 'float32')\n",
    "    testX.append(img)\n",
    "testX = np.array(testX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = trainX / 255\n",
    "testX = testX/ 255 #normalizing for fast processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we will make trainY. We dont have classification for test data\n",
    "trainY1 = train.Class\n",
    "# since to_categorical converts into one hot encoding fro numbers,\n",
    "#we first need to convert young, middle, old into numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "trainY2 = le.fit_transform(trainY1)  #fit_transform returns encoded labels\n",
    "trainY = keras.utils.to_categorical(trainY2, num_classes = 3)\n",
    "#trainY1[1] = YOUNG\n",
    "#trainY2[1] = 2\n",
    "#trainY[1] = [0.,0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "batchSize = 128\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(filters = 32, kernel_size = (3, 3), padding = 'same',\n",
    "                        input_shape = (32, 32, 3), activation = 'relu'))\n",
    "\n",
    "model.add(Convolution2D(filters = 32, kernel_size = (3, 3), padding = 'same',\n",
    "                        activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 64, kernel_size = (3, 3), padding = 'same',\n",
    "                        activation = 'relu'))\n",
    "\n",
    "model.add(Convolution2D(filters = 64, kernel_size = (3, 3), padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "model.add(Convolution2D(filters = 128, kernel_size = (3, 3), padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "\n",
    "model.add(Convolution2D(filters = 128, kernel_size = (3, 3), padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "            \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17915 samples, validate on 1991 samples\n",
      "Epoch 1/40\n",
      "17915/17915 [==============================] - 197s - loss: 0.0342 - acc: 0.9888 - val_loss: 1.0830 - val_acc: 0.8061\n",
      "Epoch 2/40\n",
      "17915/17915 [==============================] - 217s - loss: 0.0388 - acc: 0.9873 - val_loss: 1.1356 - val_acc: 0.8046\n",
      "Epoch 3/40\n",
      "17915/17915 [==============================] - 222s - loss: 0.0376 - acc: 0.9871 - val_loss: 1.1009 - val_acc: 0.8011\n",
      "Epoch 4/40\n",
      "17915/17915 [==============================] - 221s - loss: 0.0400 - acc: 0.9870 - val_loss: 1.0620 - val_acc: 0.8016\n",
      "Epoch 5/40\n",
      "17915/17915 [==============================] - 211s - loss: 0.0400 - acc: 0.9871 - val_loss: 1.1917 - val_acc: 0.7961\n",
      "Epoch 6/40\n",
      "17915/17915 [==============================] - 185s - loss: 0.0324 - acc: 0.9891 - val_loss: 1.1857 - val_acc: 0.8051\n",
      "Epoch 7/40\n",
      "17915/17915 [==============================] - 184s - loss: 0.0296 - acc: 0.9899 - val_loss: 1.1434 - val_acc: 0.8051\n",
      "Epoch 8/40\n",
      "17915/17915 [==============================] - 173s - loss: 0.0294 - acc: 0.9904 - val_loss: 1.2067 - val_acc: 0.8021\n",
      "Epoch 9/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0411 - acc: 0.9860 - val_loss: 1.1464 - val_acc: 0.8016\n",
      "Epoch 10/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0418 - acc: 0.9868 - val_loss: 0.9717 - val_acc: 0.8096\n",
      "Epoch 11/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0226 - acc: 0.9919 - val_loss: 1.1583 - val_acc: 0.8036\n",
      "Epoch 12/40\n",
      "17915/17915 [==============================] - 170s - loss: 0.0241 - acc: 0.9915 - val_loss: 1.3914 - val_acc: 0.8006\n",
      "Epoch 13/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0496 - acc: 0.9841 - val_loss: 1.0228 - val_acc: 0.8112\n",
      "Epoch 14/40\n",
      "17915/17915 [==============================] - 170s - loss: 0.0207 - acc: 0.9931 - val_loss: 1.2739 - val_acc: 0.8091\n",
      "Epoch 15/40\n",
      "17915/17915 [==============================] - 175s - loss: 0.0411 - acc: 0.9865 - val_loss: 0.9200 - val_acc: 0.8036\n",
      "Epoch 16/40\n",
      "17915/17915 [==============================] - 178s - loss: 0.0430 - acc: 0.9850 - val_loss: 1.2153 - val_acc: 0.7880\n",
      "Epoch 17/40\n",
      "17915/17915 [==============================] - 173s - loss: 0.0370 - acc: 0.9868 - val_loss: 1.1644 - val_acc: 0.8081\n",
      "Epoch 18/40\n",
      "17915/17915 [==============================] - 172s - loss: 0.0373 - acc: 0.9874 - val_loss: 1.0381 - val_acc: 0.8056\n",
      "Epoch 19/40\n",
      "17915/17915 [==============================] - 178s - loss: 0.0181 - acc: 0.9943 - val_loss: 1.3967 - val_acc: 0.8006\n",
      "Epoch 20/40\n",
      "17915/17915 [==============================] - 182s - loss: 0.0229 - acc: 0.9935 - val_loss: 1.1032 - val_acc: 0.8127\n",
      "Epoch 21/40\n",
      "17915/17915 [==============================] - 173s - loss: 0.0197 - acc: 0.9935 - val_loss: 1.2404 - val_acc: 0.8006\n",
      "Epoch 22/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0269 - acc: 0.9912 - val_loss: 1.2812 - val_acc: 0.8086\n",
      "Epoch 23/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0312 - acc: 0.9903 - val_loss: 1.1151 - val_acc: 0.8106\n",
      "Epoch 24/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0310 - acc: 0.9902 - val_loss: 1.2132 - val_acc: 0.8152\n",
      "Epoch 25/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0189 - acc: 0.9944 - val_loss: 1.4149 - val_acc: 0.8071\n",
      "Epoch 26/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0381 - acc: 0.9869 - val_loss: 1.1229 - val_acc: 0.7976\n",
      "Epoch 27/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0379 - acc: 0.9878 - val_loss: 1.1525 - val_acc: 0.7966\n",
      "Epoch 28/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0277 - acc: 0.9912 - val_loss: 1.1577 - val_acc: 0.8041\n",
      "Epoch 29/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0300 - acc: 0.9893 - val_loss: 1.2055 - val_acc: 0.8031\n",
      "Epoch 30/40\n",
      "17915/17915 [==============================] - 171s - loss: 0.0239 - acc: 0.9927 - val_loss: 1.3116 - val_acc: 0.8091\n",
      "Epoch 31/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0334 - acc: 0.9898 - val_loss: 1.0667 - val_acc: 0.8152\n",
      "Epoch 32/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0184 - acc: 0.9940 - val_loss: 1.2773 - val_acc: 0.8132\n",
      "Epoch 33/40\n",
      "17915/17915 [==============================] - 170s - loss: 0.0255 - acc: 0.9916 - val_loss: 1.2815 - val_acc: 0.8091\n",
      "Epoch 34/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0291 - acc: 0.9906 - val_loss: 1.1754 - val_acc: 0.8006\n",
      "Epoch 35/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0207 - acc: 0.9934 - val_loss: 1.3383 - val_acc: 0.8086\n",
      "Epoch 36/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0366 - acc: 0.9876 - val_loss: 1.2957 - val_acc: 0.8117\n",
      "Epoch 37/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0262 - acc: 0.9913 - val_loss: 1.2673 - val_acc: 0.8076\n",
      "Epoch 38/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0217 - acc: 0.9929 - val_loss: 1.2378 - val_acc: 0.8081\n",
      "Epoch 39/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0196 - acc: 0.9938 - val_loss: 1.2662 - val_acc: 0.8026\n",
      "Epoch 40/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0260 - acc: 0.9912 - val_loss: 1.1910 - val_acc: 0.8117\n",
      "Train on 17915 samples, validate on 1991 samples\n",
      "Epoch 1/40\n",
      "17915/17915 [==============================] - 174s - loss: 0.0251 - acc: 0.9919 - val_loss: 1.2339 - val_acc: 0.8207\n",
      "Epoch 2/40\n",
      "17915/17915 [==============================] - 171s - loss: 0.0155 - acc: 0.9945 - val_loss: 1.2823 - val_acc: 0.7981\n",
      "Epoch 3/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0275 - acc: 0.9921 - val_loss: 1.1918 - val_acc: 0.8046\n",
      "Epoch 4/40\n",
      "17915/17915 [==============================] - 171s - loss: 0.0234 - acc: 0.9925 - val_loss: 1.1592 - val_acc: 0.8051\n",
      "Epoch 5/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0290 - acc: 0.9901 - val_loss: 1.2759 - val_acc: 0.8076\n",
      "Epoch 6/40\n",
      "17915/17915 [==============================] - 175s - loss: 0.0254 - acc: 0.9919 - val_loss: 1.1324 - val_acc: 0.7996\n",
      "Epoch 7/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0188 - acc: 0.9928 - val_loss: 1.3494 - val_acc: 0.8122\n",
      "Epoch 8/40\n",
      "17915/17915 [==============================] - 170s - loss: 0.0233 - acc: 0.9925 - val_loss: 1.1027 - val_acc: 0.7976\n",
      "Epoch 9/40\n",
      "17915/17915 [==============================] - 166s - loss: 0.0324 - acc: 0.9901 - val_loss: 1.1395 - val_acc: 0.8112\n",
      "Epoch 10/40\n",
      "17915/17915 [==============================] - 166s - loss: 0.0308 - acc: 0.9908 - val_loss: 1.0943 - val_acc: 0.8096\n",
      "Epoch 11/40\n",
      "17915/17915 [==============================] - 171s - loss: 0.0325 - acc: 0.9896 - val_loss: 1.0286 - val_acc: 0.7981\n",
      "Epoch 12/40\n",
      "17915/17915 [==============================] - 170s - loss: 0.0289 - acc: 0.9902 - val_loss: 1.2668 - val_acc: 0.7946\n",
      "Epoch 13/40\n",
      "17915/17915 [==============================] - 169s - loss: 0.0245 - acc: 0.9919 - val_loss: 1.4242 - val_acc: 0.7906\n",
      "Epoch 14/40\n",
      "17915/17915 [==============================] - 170s - loss: 0.0357 - acc: 0.9887 - val_loss: 1.1245 - val_acc: 0.8016\n",
      "Epoch 15/40\n",
      "17915/17915 [==============================] - 171s - loss: 0.0142 - acc: 0.9955 - val_loss: 1.3911 - val_acc: 0.8036\n",
      "Epoch 16/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0198 - acc: 0.9935 - val_loss: 1.2387 - val_acc: 0.8086\n",
      "Epoch 17/40\n",
      "17915/17915 [==============================] - 168s - loss: 0.0184 - acc: 0.9944 - val_loss: 1.2984 - val_acc: 0.8081\n",
      "Epoch 18/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0070 - acc: 0.9976 - val_loss: 1.5906 - val_acc: 0.8011\n",
      "Epoch 19/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0324 - acc: 0.9903 - val_loss: 1.3131 - val_acc: 0.8036\n",
      "Epoch 20/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0223 - acc: 0.9937 - val_loss: 1.2822 - val_acc: 0.8096\n",
      "Epoch 21/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0276 - acc: 0.9919 - val_loss: 1.1587 - val_acc: 0.8091\n",
      "Epoch 22/40\n",
      "17915/17915 [==============================] - 167s - loss: 0.0264 - acc: 0.9917 - val_loss: 1.2651 - val_acc: 0.7976\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17915/17915 [==============================] - 168s - loss: 0.0188 - acc: 0.9941 - val_loss: 1.4082 - val_acc: 0.8001\n",
      "Epoch 24/40\n",
      " 4864/17915 [=======>......................] - ETA: 119s - loss: 0.0289 - acc: 0.9910"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    model.fit(trainX, trainY, validation_split = 0.1, batch_size = batchSize, epochs = 40,\n",
    "              verbose = 1)\n",
    "    model.save(os.getcwd() + '/saved_model/keras_face_age_model_' + str(i*40 + 40) +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(os.getcwd() + '/saved_model/keras_face_age_model_40.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
